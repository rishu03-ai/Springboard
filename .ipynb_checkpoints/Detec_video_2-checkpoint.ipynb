{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20de71ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6efef8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/1: https://youtu.be/IKj_z2hgYUM... Success  (517 frames of shape 1920x1080 at 29.97 FPS)\n",
      "\n",
      "WARNING \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 173.6ms\n",
      "0: 384x640 1 person, 1 tie, 102.5ms\n",
      "0: 384x640 1 person, 2 ties, 87.0ms\n",
      "0: 384x640 1 person, 1 tie, 86.0ms\n",
      "0: 384x640 1 person, 1 tie, 80.6ms\n",
      "0: 384x640 1 person, 1 tie, 83.6ms\n",
      "0: 384x640 1 person, 1 tie, 80.8ms\n",
      "0: 384x640 1 person, 1 tie, 87.9ms\n",
      "0: 384x640 1 person, 1 tie, 82.8ms\n",
      "0: 384x640 1 person, 1 tie, 85.2ms\n",
      "0: 384x640 1 person, 1 tie, 76.9ms\n",
      "0: 384x640 1 person, 1 tie, 79.0ms\n",
      "0: 384x640 1 person, 1 tie, 80.8ms\n",
      "0: 384x640 1 person, 1 tie, 82.3ms\n",
      "0: 384x640 1 person, 1 tie, 80.8ms\n",
      "0: 384x640 1 person, 1 tie, 86.5ms\n",
      "0: 384x640 1 person, 1 tie, 81.6ms\n",
      "0: 384x640 1 person, 1 tie, 85.4ms\n",
      "0: 384x640 1 person, 1 tie, 80.6ms\n",
      "0: 384x640 1 person, 1 tie, 104.3ms\n",
      "0: 384x640 1 person, 1 tie, 80.2ms\n",
      "0: 384x640 1 person, 1 tie, 77.2ms\n",
      "0: 384x640 1 person, 1 tie, 81.7ms\n",
      "0: 384x640 1 person, 1 tie, 74.8ms\n",
      "0: 384x640 1 person, 1 tie, 74.3ms\n",
      "0: 384x640 1 person, 1 tie, 82.3ms\n",
      "0: 384x640 1 person, 1 tie, 74.7ms\n",
      "0: 384x640 1 person, 1 tie, 73.9ms\n",
      "0: 384x640 1 person, 1 tie, 79.2ms\n",
      "0: 384x640 1 person, 1 tie, 81.0ms\n",
      "0: 384x640 1 person, 1 tie, 71.2ms\n",
      "0: 384x640 1 person, 1 tie, 67.5ms\n",
      "Speed: 2.3ms preprocess, 84.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\yolov11n_live_output18\u001b[0m\n",
      "Processing complete.\n",
      "The video was displayed in real-time during processing because 'show=True'.\n",
      "A saved copy of the video with detections is in 'runs/detect/yolov11n_live_output/'.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the nano version of the YOLOv11 model\n",
    "model = YOLO(\"yolo11n.pt\") \n",
    "\n",
    "# Define the path to your input video\n",
    "video_path = \"https://youtu.be/IKj_z2hgYUM\"\n",
    "\n",
    "# Run inference on the video\n",
    "results = model.predict(\n",
    "    source=video_path,\n",
    "    save=True,  # This will save the output video file (with boxes) to disk.\n",
    "    show=True,  # **THIS IS THE KEY PART** - It opens a window and displays\n",
    "                # the video with the bounding boxes as the processing happens.\n",
    "    conf=0.25,\n",
    "    name='yolov11n_live_output'\n",
    ")\n",
    "\n",
    "print(\"Processing complete.\")\n",
    "print(\"The video was displayed in real-time during processing because 'show=True'.\")\n",
    "print(\"A saved copy of the video with detections is in 'runs/detect/yolov11n_live_output/'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca0483-f1e8-4b30-ad12-b9f05ee17cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the nano version of the YOLOv11 model\n",
    "model = YOLO(\"yolo11n.pt\") \n",
    "\n",
    "# Define the path to your input video\n",
    "video_path = \"WhatsApp Video 2025-12-03 at 16.06.15_f67dc92b.mp4\"\n",
    "\n",
    "# Run inference on the video\n",
    "results = model.predict(\n",
    "    source=video_path,\n",
    "    save=True,  # This will save the output video file (with boxes) to disk.\n",
    "    show=True,  # **THIS IS THE KEY PART** - It opens a window and displays\n",
    "                # the video with the bounding boxes as the processing happens.\n",
    "    conf=0.25,\n",
    "    name='yolov11n_live_output'\n",
    ")\n",
    "\n",
    "print(\"Processing complete.\")\n",
    "print(\"The video was displayed in real-time during processing because 'show=True'.\")\n",
    "print(\"A saved copy of the video with detections is in 'runs/detect/yolov11n_live_output/'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab0adf0-1c54-4a25-8890-13c4ffef09b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
