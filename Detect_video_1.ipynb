{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca0483-f1e8-4b30-ad12-b9f05ee17cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 3 persons, 1 train, 1 backpack, 117.9ms\n",
      "video 1/1 (frame 2/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 4 persons, 1 train, 2 backpacks, 92.4ms\n",
      "video 1/1 (frame 3/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 4 persons, 1 train, 1 backpack, 107.5ms\n",
      "video 1/1 (frame 4/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 3 persons, 1 train, 2 backpacks, 95.6ms\n",
      "video 1/1 (frame 5/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 4 persons, 1 train, 1 backpack, 114.1ms\n",
      "video 1/1 (frame 6/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 3 persons, 1 train, 2 backpacks, 82.4ms\n",
      "video 1/1 (frame 7/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 3 persons, 1 train, 1 backpack, 101.1ms\n",
      "video 1/1 (frame 8/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 3 persons, 2 trains, 2 backpacks, 1 handbag, 71.9ms\n",
      "video 1/1 (frame 9/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 2 persons, 1 train, 1 backpack, 120.2ms\n",
      "video 1/1 (frame 10/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 3 persons, 1 train, 1 handbag, 131.0ms\n",
      "video 1/1 (frame 11/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 3 persons, 1 train, 100.7ms\n",
      "video 1/1 (frame 12/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 3 persons, 1 train, 1 backpack, 120.3ms\n",
      "video 1/1 (frame 13/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 3 persons, 1 train, 1 backpack, 1 handbag, 111.6ms\n",
      "video 1/1 (frame 14/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 4 persons, 2 trains, 1 backpack, 94.4ms\n",
      "video 1/1 (frame 15/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 5 persons, 2 trains, 112.9ms\n",
      "video 1/1 (frame 16/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 5 persons, 2 trains, 1 backpack, 78.0ms\n",
      "video 1/1 (frame 17/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 7 persons, 1 train, 1 backpack, 86.3ms\n",
      "video 1/1 (frame 18/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 5 persons, 1 train, 1 backpack, 91.3ms\n",
      "video 1/1 (frame 19/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 6 persons, 2 trains, 1 backpack, 74.8ms\n",
      "video 1/1 (frame 20/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 7 persons, 2 trains, 74.1ms\n",
      "video 1/1 (frame 21/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 6 persons, 1 train, 1 backpack, 1 handbag, 83.3ms\n",
      "video 1/1 (frame 22/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 4 persons, 1 train, 1 backpack, 1 handbag, 71.1ms\n",
      "video 1/1 (frame 23/150) C:\\Users\\Rishabh Thapliyal\\Desktop\\Springboard\\Video2.mp4: 640x384 5 persons, 1 train, 2 backpacks, 72.6ms\n",
      "Speed: 2.6ms preprocess, 95.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 384)\n",
      "Results saved to \u001b[1mruns\\detect\\yolov11n_live_output20\u001b[0m\n",
      "Processing complete.\n",
      "The video was displayed in real-time during processing because 'show=True'.\n",
      "A saved copy of the video with detections is in 'runs/detect/yolov11n_live_output/'.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the nano version of the YOLOv11 model\n",
    "model = YOLO(\"yolo11n.pt\") \n",
    "\n",
    "# Define the path to your input video\n",
    "video_path = \"Video1.mp4\"\n",
    "\n",
    "# Run inference on the video\n",
    "results = model.predict(\n",
    "    source=video_path,\n",
    "    save=True,  # This will save the output video file (with boxes) to disk.\n",
    "    show=True,  # **THIS IS THE KEY PART** - It opens a window and displays\n",
    "                # the video with the bounding boxes as the processing happens.\n",
    "    conf=0.25,\n",
    "    name='yolov11n_live_output'\n",
    ")\n",
    "\n",
    "print(\"Processing complete.\")\n",
    "print(\"The video was displayed in real-time during processing because 'show=True'.\")\n",
    "print(\"A saved copy of the video with detections is in 'runs/detect/yolov11n_live_output/'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab0adf0-1c54-4a25-8890-13c4ffef09b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
